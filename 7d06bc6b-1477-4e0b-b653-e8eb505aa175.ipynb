{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c6c5ee",
   "metadata": {},
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-4\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся [здесь](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` собрана информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a3f17",
   "metadata": {},
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке: \n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке. \n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff2c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os.path\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b0eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\akras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7db0e",
   "metadata": {},
   "source": [
    "Определим список `констант` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823baddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ссылка на скачивание данных\n",
    "DATA_URL='https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip'\n",
    "ROOT_FOLDER='./dsplus_integrated_project_4'\n",
    "# исключаем повторную загрузку, если файл уже был ранее загружен\n",
    "OUT_FILE=os.path.exists(ROOT_FOLDER + '.zip')\n",
    "TRAIN_IMAGE_FOLDER=ROOT_FOLDER + '/to_upload/train_images'\n",
    "RANDOM_STATE=12345\n",
    "TMP='./cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e119a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cjplаём временный каталог\n",
    "Path(TMP).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0310d",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2c8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUT_FILE == False:\n",
    "    # скачиваем архив\n",
    "    urllib.request.urlretrieve(DATA_URL, 'dsplus_integrated_project_4.zip')\n",
    "    # распаковываем\n",
    "    with zipfile.ZipFile('./dsplus_integrated_project_4.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0da4d",
   "metadata": {},
   "source": [
    "### Изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd63937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       5822 non-null   object\n",
      " 1   query_id    5822 non-null   object\n",
      " 2   query_text  5822 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262583859_653f1469a9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2447284966_d6bbdb4b6e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549968784_39bfbe44f9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621415349_ef1a7e73be.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "\n",
       "                                          query_text  \n",
       "0  A young child is wearing blue goggles and sitt...  \n",
       "1  A young child is wearing blue goggles and sitt...  \n",
       "2  A young child is wearing blue goggles and sitt...  \n",
       "3  A young child is wearing blue goggles and sitt...  \n",
       "4  A young child is wearing blue goggles and sitt...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_csv = pd.read_csv(ROOT_FOLDER + '/to_upload/train_dataset.csv')\n",
    "\n",
    "train_dataset_csv.info()\n",
    "\n",
    "train_dataset_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b82d8e",
   "metadata": {},
   "source": [
    "#### Краудсорсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d739464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47830 entries, 0 to 47829\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   image     47830 non-null  object \n",
      " 1   query_id  47830 non-null  object \n",
      " 2   positive  47830 non-null  float64\n",
      " 3   n1        47830 non-null  int64  \n",
      " 4   n2        47830 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>positive</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  positive  n1  n2\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2       1.0   3   0\n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2       0.0   0   3\n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2       0.0   0   3\n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2       0.0   0   3\n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2       0.0   0   3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_annotations_tsv = pd.read_csv(ROOT_FOLDER + '/to_upload/CrowdAnnotations.tsv', \n",
    "                                    sep='\\t', \n",
    "                                    header=None, \n",
    "                                    names=['image', 'query_id', 'positive', 'n1', 'n2'])\n",
    "\n",
    "crowd_annotations_tsv.info()\n",
    "\n",
    "crowd_annotations_tsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec1d9e",
   "metadata": {},
   "source": [
    "Описание колонок:\n",
    "* `image` - Имя файла изображения;\n",
    "* `query_id` - Идентификатор описания;\n",
    "* `positive` - Доля людей, подтвердивших, что описание соответствует изображению;\n",
    "* `n1` - Количество человек, подтвердивших, что описание соответствует изображению;\n",
    "* `n2` - Количество человек, подтвердивших, что описание не соответствует изображению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d1c95",
   "metadata": {},
   "source": [
    "#### Оценка экспертов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bbeb74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   image     5822 non-null   object\n",
      " 1   query_id  5822 non-null   object\n",
      " 2   n1        5822 non-null   int64 \n",
      " 3   n2        5822 non-null   int64 \n",
      " 4   n3        5822 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 227.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  n1  n2  n3\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   1   1   1\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2   1   1   2\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   1   1   2\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2   1   2   2\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2   1   1   2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_annotations_tsv = pd.read_csv(ROOT_FOLDER + '/to_upload/ExpertAnnotations.tsv', \n",
    "                                     sep='\\t', \n",
    "                                     header=None, \n",
    "                                     names=['image', 'query_id', 'n1', 'n2', 'n3'])\n",
    "\n",
    "expert_annotations_tsv.reset_index(inplace=True, drop=True)\n",
    "\n",
    "expert_annotations_tsv.info()\n",
    "\n",
    "expert_annotations_tsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae553fd",
   "metadata": {},
   "source": [
    "Описание колонок:\n",
    "* `image` - Имя файла изображения;\n",
    "* `query_id` - Идентификатор описания;\n",
    "* `n1` — оценка 1 эксперта;\n",
    "* `n2` — оценка 2 эксперта;\n",
    "* `n3` — оценка 3 эксперта."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7445c9",
   "metadata": {},
   "source": [
    "Выполним обработку данных краудсорсинга:\n",
    "* добавим колонку `n0` с агрегированной оценкой;\n",
    "* добавим колонку `positive` с долей, подтвердивших, что описание соотвествует изображению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79592721",
   "metadata": {},
   "source": [
    "Эксперты ставят оценки по шкале от `1` до `4`, где \n",
    "* `1` — изображение и запрос совершенно не соответствуют друг другу;\n",
    "* `2` — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует; \n",
    "* `3` — запрос и текст соответствуют с точностью до некоторых деталей;\n",
    "* `4` — запрос и текст соответствуют полностью.\n",
    "\n",
    "___Примечание___: \"положительными\" будем считать оценки `3` и `4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afadaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполним обработку данных краудсорсинга\n",
    "def calc_avg(row):\n",
    "    \"\"\"\n",
    "    Вычисление результата \"голосования\" способом большинства\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    row: Series\n",
    "    \n",
    "    Результат:\n",
    "    ----------\n",
    "    int - число\n",
    "    \"\"\"\n",
    "    array = [row['n1'], row['n2'], row['n3']]\n",
    "    u, c = np.unique(array, return_counts=True)\n",
    "\n",
    "    # находим самую частую оценку\n",
    "    y = u[c == c.max()]\n",
    "    # вычисляем долю найденных оценок\n",
    "    percentages = dict(zip(u, c / len(array)))\n",
    "    \n",
    "    # \"позитивными\" будем считать, тех у кого оценка 3 или 4\n",
    "    row['n0'] = y[0] if len(y) == 1 else 0\n",
    "    row['positive'] = percentages[y[0]] if len(y) == 1 and y[0] in [3, 4] else 0\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3785b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_annotations_tsv = expert_annotations_tsv.apply(calc_avg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f559a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n0</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1119015538_e8e796281e.jpg</td>\n",
       "      <td>2534502836_7a75305655.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1122944218_8eb3607403.jpg</td>\n",
       "      <td>3325497914_f9014d615b.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1287475186_2dee85f1a5.jpg</td>\n",
       "      <td>2918769188_565dd48060.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1329832826_432538d331.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image                     query_id  n1  n2  n3  n0  \\\n",
       "17   1082379191_ec1e53f996.jpg  1536774449_e16b1b6382.jpg#2   1   2   3   0   \n",
       "40   1119015538_e8e796281e.jpg  2534502836_7a75305655.jpg#2   2   3   4   0   \n",
       "47   1122944218_8eb3607403.jpg  3325497914_f9014d615b.jpg#2   2   3   4   0   \n",
       "168  1287475186_2dee85f1a5.jpg  2918769188_565dd48060.jpg#2   1   2   3   0   \n",
       "199  1329832826_432538d331.jpg  1536774449_e16b1b6382.jpg#2   1   2   3   0   \n",
       "\n",
       "     positive  \n",
       "17        0.0  \n",
       "40        0.0  \n",
       "47        0.0  \n",
       "168       0.0  \n",
       "199       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# удалим те мнения экспертов, где они полностью разошлись\n",
    "expert_annotations_n0 = expert_annotations_tsv[expert_annotations_tsv['n0'] == 0]\n",
    "\n",
    "display(expert_annotations_n0.head())\n",
    "\n",
    "expert_annotations_tsv.drop(expert_annotations_n0.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1536327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5696 entries, 0 to 5821\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   image     5696 non-null   object \n",
      " 1   query_id  5696 non-null   object \n",
      " 2   n1        5696 non-null   int64  \n",
      " 3   n2        5696 non-null   int64  \n",
      " 4   n3        5696 non-null   int64  \n",
      " 5   n0        5696 non-null   int64  \n",
      " 6   positive  5696 non-null   float64\n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 356.0+ KB\n"
     ]
    }
   ],
   "source": [
    "expert_annotations_tsv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a13b7e",
   "metadata": {},
   "source": [
    "### Объединение оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26050c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства установим индексы\n",
    "crowd_annotations_tsv.set_index(['image', 'query_id'], inplace=True)\n",
    "expert_annotations_tsv.set_index(['image', 'query_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fdefba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = crowd_annotations_tsv[['positive']].merge(\n",
    "    expert_annotations_tsv[['positive']], \n",
    "    how='outer', # используем это объединение, так как нужно соеденить все данные независимо от ключа\n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    suffixes=('_crowd', '_expert')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cdb6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_positive_expert_priority(row):\n",
    "    \"\"\"\n",
    "    Объединение оценок с приоритетом для экспертов\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    row: Series\n",
    "    \n",
    "    Результат:\n",
    "    ----------\n",
    "    int - число\n",
    "    \"\"\"\n",
    "    crowd = row['positive_crowd']\n",
    "    expert = row['positive_expert']\n",
    "    \n",
    "    if expert >= 0:\n",
    "        # важны только экспертные мнения\n",
    "        return expert\n",
    "    \n",
    "    # если эксперты не давали оценку, а результат есть на кроудсорсинге\n",
    "    if crowd >= 0 and expert != expert:\n",
    "        return crowd\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa5334fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['positive'] = annotations.apply(join_positive_expert_priority, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac1b9e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 51268 entries, ('1056338697_4f7d7ce270.jpg', '1056338697_4f7d7ce270.jpg#2') to ('997722733_0cb5439472.jpg', '997722733_0cb5439472.jpg#2')\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   positive_crowd   47830 non-null  float64\n",
      " 1   positive_expert  5696 non-null   float64\n",
      " 2   positive         51268 non-null  float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "555f83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_csv.set_index(['image', 'query_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a02d58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset_csv.merge(annotations['positive'], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8380cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3670907052_c827593564.jpg</th>\n",
       "      <th>150387174_24825cf871.jpg#2</th>\n",
       "      <td>A man is riding a dirt bike over some rocks .</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545652636_0746537307.jpg</th>\n",
       "      <th>2774430374_fee1d793e7.jpg#2</th>\n",
       "      <td>A little boy preparing to hit a baseball</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245252561_4f20f1c89e.jpg</th>\n",
       "      <th>3363750526_efcedc47a9.jpg#2</th>\n",
       "      <td>Black and white dog on wet sand .</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          query_text  \\\n",
       "image                     query_id                                                                     \n",
       "3670907052_c827593564.jpg 150387174_24825cf871.jpg#2   A man is riding a dirt bike over some rocks .   \n",
       "3545652636_0746537307.jpg 2774430374_fee1d793e7.jpg#2       A little boy preparing to hit a baseball   \n",
       "245252561_4f20f1c89e.jpg  3363750526_efcedc47a9.jpg#2              Black and white dog on wet sand .   \n",
       "\n",
       "                                                       positive  \n",
       "image                     query_id                               \n",
       "3670907052_c827593564.jpg 150387174_24825cf871.jpg#2   0.666667  \n",
       "3545652636_0746537307.jpg 2774430374_fee1d793e7.jpg#2  0.666667  \n",
       "245252561_4f20f1c89e.jpg  3363750526_efcedc47a9.jpg#2  0.666667  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем наличие данных\n",
    "train_dataset[train_dataset['positive'] > 0].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65759307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 5822 entries, ('1056338697_4f7d7ce270.jpg', '2549968784_39bfbe44f9.jpg#2') to ('968081289_cdba83ce2e.jpg', '2292406847_f366350600.jpg#2')\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   query_text  5822 non-null   object \n",
      " 1   positive    5767 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 322.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cab4a7",
   "metadata": {},
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    "> \n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45344161",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'baby', \n",
    "    'child', \n",
    "    'little boy', \n",
    "    'little girl', \n",
    "    'kid', \n",
    "    'young girl', \n",
    "    'young boy', \n",
    "    'boy', \n",
    "    'girl'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "859afa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ban(txt):\n",
    "    \"\"\"\n",
    "    Определение наличие стоп-слов\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    txt: string - текст для анализа\n",
    "    \n",
    "    Результат:\n",
    "    ----------\n",
    "    boolean - результат обработки\n",
    "    \"\"\"\n",
    "    txt = txt.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(txt)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_tokens])\n",
    "    \n",
    "    for word in stop_words:\n",
    "        word_len = len(word.split())\n",
    "        \n",
    "        if word_len > 1:\n",
    "            if word in txt:\n",
    "                return True\n",
    "        elif word_len == 1:\n",
    "            if word in txt.split():\n",
    "                return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "342140e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1200 entries, ('1056338697_4f7d7ce270.jpg', '2549968784_39bfbe44f9.jpg#2') to ('757046028_ff5999f91b.jpg', '2061144717_5b3a1864f0.jpg#2')\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   query_text  1200 non-null   object \n",
      " 1   positive    1185 non-null   float64\n",
      " 2   ban         1200 non-null   bool   \n",
      "dtypes: bool(1), float64(1), object(1)\n",
      "memory usage: 104.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset['ban'] = train_dataset['query_text'].apply(ban)\n",
    "\n",
    "train_dataset[train_dataset['ban'] == True].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "485a8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.drop(train_dataset[train_dataset.ban == True].index, inplace=True)\n",
    "\n",
    "train_dataset.drop(columns=['ban'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d85de",
   "metadata": {},
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1678fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize the model with the best available weights\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Create the feature extractor with the required nodes\n",
    "return_nodes = {'flatten': 'flatten'}\n",
    "feature_extractor = create_feature_extractor(model, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba864ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_vector(image_path):\n",
    "    \"\"\"\n",
    "    Получение вектора изображения\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    image_path: string - путь к изображению\n",
    "    \n",
    "    Результат:\n",
    "    ----------\n",
    "    torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 4: Load the image(s) and apply inference preprocessing transforms\n",
    "    image = read_image(image_path).unsqueeze(0)\n",
    "    model_input = preprocess(image)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Step 5: Extract the features\n",
    "        features = feature_extractor(model_input)\n",
    "        flatten_fts = features[\"flatten\"].squeeze()\n",
    "        return flatten_fts.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "527a063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_vector(TRAIN_IMAGE_FOLDER + '/53043785_c468d6f931.jpg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7062765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь для хранения результата обработки\n",
    "image_vectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e582f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images2vector(folder):\n",
    "    count = 0\n",
    "    \n",
    "    for p in Path(TRAIN_IMAGE_FOLDER).glob('*.jpg'):\n",
    "        count+=1\n",
    "        \n",
    "    with tqdm(total=count) as pbar:\n",
    "        for p in Path(TRAIN_IMAGE_FOLDER).glob('*.jpg'):\n",
    "            image_vectors[p.name] = get_image_vector(TRAIN_IMAGE_FOLDER + f'/{p.name}')\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ecaa093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем кэш\n",
    "if os.path.exists(TMP + '/image_vectors.pickle'):\n",
    "    image_vectors = pickle.load(open(TMP + '/image_vectors.pickle', 'rb'))\n",
    "else:\n",
    "    images2vector(TRAIN_IMAGE_FOLDER)\n",
    "    pickle.dump(image_vectors, file = open(TMP + '/image_vectors.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43dcb207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = list(image_vectors.keys())[0]\n",
    "image_vectors[img1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d71dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация изображения на заранее обученной модели resnet18 позволило сделать вектор длинной 512\n",
      "Уменьшение вектора позволит сэкономить ресурсы и вычислительное время при обучении.\n"
     ]
    }
   ],
   "source": [
    "print(f'''Векторизация изображения на заранее обученной модели resnet18 позволило сделать вектор длинной {image_vectors[img1].shape[0]}\n",
    "Уменьшение вектора позволит сэкономить ресурсы и вычислительное время при обучении.''') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486b83b",
   "metadata": {},
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c91c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучать будем на специальной модели \n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "995c4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10474e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vector(sentences):\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    pbar.update(1)\n",
    "    return sentence_embeddings[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79402539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем кэш\n",
    "if os.path.exists(TMP + '/train_dataset.pickle'):\n",
    "    train_dataset = pickle.load(open(TMP + '/train_dataset.pickle', 'rb'))\n",
    "else:\n",
    "    with tqdm(total=train_dataset.shape[0]) as pbar:\n",
    "        train_dataset['text2vec'] = train_dataset['query_text'].apply(lambda x: text2vector(x))\n",
    "        \n",
    "    pickle.dump(train_dataset, file = open(TMP + '/train_dataset.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99ab37a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>positive</th>\n",
       "      <th>text2vec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056338697_4f7d7ce270.jpg</th>\n",
       "      <th>3181701312_70a379ab6e.jpg#2</th>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187395715_f2940c2b72.jpg</th>\n",
       "      <th>3181701312_70a379ab6e.jpg#2</th>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463978865_c87c6ca84c.jpg</th>\n",
       "      <th>3181701312_70a379ab6e.jpg#2</th>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488590040_35a3e96c89.jpg</th>\n",
       "      <th>3181701312_70a379ab6e.jpg#2</th>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534875358_6ea30d3091.jpg</th>\n",
       "      <th>3181701312_70a379ab6e.jpg#2</th>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            query_text  \\\n",
       "image                     query_id                                                                       \n",
       "1056338697_4f7d7ce270.jpg 3181701312_70a379ab6e.jpg#2  A man sleeps under a blanket on a city street .   \n",
       "3187395715_f2940c2b72.jpg 3181701312_70a379ab6e.jpg#2  A man sleeps under a blanket on a city street .   \n",
       "463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2  A man sleeps under a blanket on a city street .   \n",
       "488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2  A man sleeps under a blanket on a city street .   \n",
       "534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2  A man sleeps under a blanket on a city street .   \n",
       "\n",
       "                                                       positive  \\\n",
       "image                     query_id                                \n",
       "1056338697_4f7d7ce270.jpg 3181701312_70a379ab6e.jpg#2       0.0   \n",
       "3187395715_f2940c2b72.jpg 3181701312_70a379ab6e.jpg#2       0.0   \n",
       "463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2       0.0   \n",
       "488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2       0.0   \n",
       "534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2       0.0   \n",
       "\n",
       "                                                                                                text2vec  \n",
       "image                     query_id                                                                        \n",
       "1056338697_4f7d7ce270.jpg 3181701312_70a379ab6e.jpg#2  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "3187395715_f2940c2b72.jpg 3181701312_70a379ab6e.jpg#2  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2  [0.15153743, -0.09737309, -0.015055661, -0.024...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1745c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер вектора для текста равен (768,)\n"
     ]
    }
   ],
   "source": [
    "sample_text_vector = train_dataset.iloc[12]['text2vec']\n",
    "print(f'Размер вектора для текста равен {sample_text_vector.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c907a",
   "metadata": {},
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad554a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1cfbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vector(row):\n",
    "    img = row['image']\n",
    "    return image_vectors[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "653d80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['image2vec'] = train_dataset.apply(image2vector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12b54e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_vectors(row):\n",
    "    \"\"\"\n",
    "    Расширяем текстовый вектор для размера изображения\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    vec: Tensor - вектор текста\n",
    "    \n",
    "    Результаты:\n",
    "    Tensor - измененный вектор \n",
    "    \"\"\"\n",
    "    return np.concatenate((row['text2vec'], row['image2vec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "161f164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['vec'] = train_dataset.apply(join_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9703cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13afb139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>positive</th>\n",
       "      <th>text2vec</th>\n",
       "      <th>image2vec</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "      <td>[0.6495988, 2.9601586, 2.8580384, 1.0457027, 0...</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "      <td>[0.33784205, 2.4333935, 1.576568, 1.210483, 1....</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "      <td>[1.0734942, 3.6644003, 1.2788564, 0.8694293, 0...</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "      <td>[1.435459, 1.1560897, 0.18595669, 0.26839632, ...</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "      <td>[0.3410133, 3.5775602, 1.0564489, 0.551388, 0....</td>\n",
       "      <td>[0.15153743, -0.09737309, -0.015055661, -0.024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "1  3187395715_f2940c2b72.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "2   463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "3   488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "4   534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "\n",
       "                                        query_text  positive  \\\n",
       "0  A man sleeps under a blanket on a city street .       0.0   \n",
       "1  A man sleeps under a blanket on a city street .       0.0   \n",
       "2  A man sleeps under a blanket on a city street .       0.0   \n",
       "3  A man sleeps under a blanket on a city street .       0.0   \n",
       "4  A man sleeps under a blanket on a city street .       0.0   \n",
       "\n",
       "                                            text2vec  \\\n",
       "0  [0.15153743, -0.09737309, -0.015055661, -0.024...   \n",
       "1  [0.15153743, -0.09737309, -0.015055661, -0.024...   \n",
       "2  [0.15153743, -0.09737309, -0.015055661, -0.024...   \n",
       "3  [0.15153743, -0.09737309, -0.015055661, -0.024...   \n",
       "4  [0.15153743, -0.09737309, -0.015055661, -0.024...   \n",
       "\n",
       "                                           image2vec  \\\n",
       "0  [0.6495988, 2.9601586, 2.8580384, 1.0457027, 0...   \n",
       "1  [0.33784205, 2.4333935, 1.576568, 1.210483, 1....   \n",
       "2  [1.0734942, 3.6644003, 1.2788564, 0.8694293, 0...   \n",
       "3  [1.435459, 1.1560897, 0.18595669, 0.26839632, ...   \n",
       "4  [0.3410133, 3.5775602, 1.0564489, 0.551388, 0....   \n",
       "\n",
       "                                                 vec  \n",
       "0  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "1  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "2  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "3  [0.15153743, -0.09737309, -0.015055661, -0.024...  \n",
       "4  [0.15153743, -0.09737309, -0.015055661, -0.024...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a6f82d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина итогового вектора равна 768 + 512 = 1280\n"
     ]
    }
   ],
   "source": [
    "print(f'Длина итогового вектора равна {df.iloc[0][\"text2vec\"].shape[0]} + {df.iloc[0][\"image2vec\"].shape[0]} = {len(df.iloc[0][\"vec\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8648b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем те записи, у которых нет оценки (это ранне удалённые записи у экспертов, которые разошлись в оценке)\n",
    "df.drop(df[df['positive'].isna()].index, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e39d9a",
   "metadata": {},
   "source": [
    "После объединения векторов с целовой переменной получили данные в виде двух одномерных векторов, разной размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3658f58",
   "metadata": {},
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92e1abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stacc.ee/extract-feature-vector-image-pytorch/\n",
    "# https://discuss.pytorch.org/t/combining-text-feature-vectors-and-image-feature-vectors/43374/2\n",
    "# https://www.codecamp.ru/blog/cosine-similarity-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0b3bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=RANDOM_STATE)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['positive']), y=df['positive'], groups=df['image']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6df34f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akras\\AppData\\Local\\Temp\\ipykernel_19144\\116904240.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  features_train = torch.FloatTensor(list(train_df.loc[:, 'vec'].values))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "features_train = torch.FloatTensor(list(train_df.loc[:, 'vec'].values))\n",
    "features_test = torch.FloatTensor(list(test_df.loc[:, 'vec'].values))\n",
    "\n",
    "target_train = torch.FloatTensor(train_df['positive'].values).reshape(-1, 1) \n",
    "target_test = torch.FloatTensor(test_df['positive'].values).reshape(-1, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "223963fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e21c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy. linalg import norm\n",
    "\n",
    "pred = model.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39dee9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760.5206"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(target_test - pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b27273",
   "metadata": {},
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9a31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94548662",
   "metadata": {},
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
